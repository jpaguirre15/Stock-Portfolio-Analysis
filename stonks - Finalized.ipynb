{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Robinhood Portfolio Using robin_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project by: Pete Aguirre II\n",
    "\n",
    "In this project, I will do a retuern:risk analysis on my current Robinhood stock portfolio with the help of multiple \n",
    "tools using:\n",
    "- Python 3\n",
    "- Jupyter Lab/Notebook\n",
    "- Beautiful Soup\n",
    "- Markowitz Efficent Frontier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO LIST:\n",
    "- Create a daily, weekly, quarterly, yearly portfolio performance\n",
    "- Learn how to create pie graphs\n",
    "- Create interactive dashboards \n",
    "- Fix bugs on diversifiable and non-diversifiable ortfolio risk analysis \n",
    "- Learn Monte Carlo Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing libraries \n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "# pip install matplotlib\n",
    "# pip install robin_stocks\n",
    "\n",
    "# Libraries Used \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import robin_stocks as r \n",
    "import pyotp\n",
    "\n",
    "from pandas_datareader import data as wb\n",
    "\n",
    "# Magic\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Data Collection (updated)\n",
    "Notes: Log in with Robinhood and portfolio will be gathered automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robinhood Log In \n",
    "email = input(\"Enter email: \")\n",
    "password = input(\"Enter password: \")\n",
    "\n",
    "totp = pyotp.TOTP(\"My2factorAppHere\").now()\n",
    "log_in = r.login(email, password, expiresIn=500, by_sms=True, mfa_code=totp)\n",
    "\n",
    "# Get stocks value\n",
    "stonks = r.build_holdings()\n",
    "\n",
    "# Logout \n",
    "r.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company tickers\n",
    "# Since the company tickers are the keys, and the other variables are values, \n",
    "# create a dataframe for symbols first.\n",
    "symbols_df = []\n",
    "for k in  stonks.keys():\n",
    "    symbols_df.append(k)\n",
    "symbols_df = np.array(symbols_df)\n",
    "symbols_df = pd.DataFrame(symbols_df, columns=['Symbol'])\n",
    "symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other headers \n",
    "# Create a dataframe for the other headers (which are values to the symbol keys).\n",
    "# Drop some variables: percent_change, equity_change, type, and id \n",
    "# Rename the variables to something nicer looking\n",
    "variables_df = pd.DataFrame.from_dict(stonks.values())\n",
    "variables_df = variables_df.drop(['percent_change', 'equity_change', 'type', 'id'], axis=1)\n",
    "variables_df = variables_df.rename(columns={'price':'Price', 'quantity':'Quantity', 'average_buy_price':'Average Price', 'equity':'Equity', 'name':'Name', 'pe_ratio':'P/E', 'percentage':'Percentage'})\n",
    "variables_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate both DataFrames \n",
    "my_portfolio = pd.concat([symbols_df, variables_df], axis=1)\n",
    "my_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable types\n",
    "my_portfolio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change some values to floats and round them to 2 decimal numbers\n",
    "my_portfolio['Price'] = my_portfolio['Price'].astype(float)\n",
    "my_portfolio['Quantity'] = my_portfolio['Quantity'].astype(float)\n",
    "my_portfolio['Average Price'] = round(my_portfolio['Average Price'].astype(float), 2)\n",
    "my_portfolio['Equity'] = round(my_portfolio['Equity'].astype(float), 2)\n",
    "my_portfolio['P/E'] = my_portfolio['P/E'].astype(float)\n",
    "my_portfolio['Percentage'] = round(my_portfolio['Percentage'].astype(float), 2)\n",
    "my_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check once more\n",
    "# Note: at this point, numbers should be floats\n",
    "my_portfolio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_portfolio = my_portfolio[[\"Name\",\"Symbol\",\"Price\",\"Quantity\",\"Average Price\",\"Equity\",\"P/E\",\"Percentage\"]]\n",
    "my_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any '.' to '-' in symbols\n",
    "#sym = my_portfolio['Symbol']\n",
    "my_portfolio['Symbol'] = my_portfolio['Symbol'].str.replace(\".\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that '.' has been replaced by '-' on symbol\n",
    "my_portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Data Collection of Historical Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect historical prices\n",
    "tickers = my_portfolio['Symbol']\n",
    "start_date = '2000-01-01'\n",
    "my_data = pd.DataFrame()\n",
    "for t in tickers:\n",
    "    my_data[t] = wb.DataReader(t, data_source='yahoo', start=start_date)['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_data = my_data.dropna()\n",
    "my_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sec_returns = np.log(my_data/my_data.shift(1))\n",
    "sec_returns\n",
    "\n",
    "sec_returns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_returns.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tickers:\n",
    "\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"#\",t)\n",
    "    print(\"DAILY\")\n",
    "    print(\"Daily Return:\", round(sec_returns[t].mean()*100, 4), \"%\")\n",
    "    print(\"Daily Risk:\", round(sec_returns[t].std()*100, 4), \"%\")\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"ANNUAL\")\n",
    "    mean_return = round((sec_returns[t].mean()*250)*100, 4)\n",
    "    std_return = round((sec_returns[t].std()*250**.5)*100, 4)\n",
    "    print(\"Annual Return:\", mean_return, \"%\")\n",
    "    print(\"Annual Risk:\", std_return, \"%\")\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sec_returns.idxmin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_returns.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance \n",
    "# Determines if there is a relationship between two stocks, whether they move together:\n",
    "# positively, negatively, or neutral \n",
    "return_cov = sec_returns.cov()\n",
    "return_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance \n",
    "# Determines if there is a relationship between two stocks, whether they move together:\n",
    "# positively, negatively, or neutral \n",
    "return_cov = sec_returns.cov()*250\n",
    "return_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlations\n",
    "# Determines how close the relationship are between two stocks\n",
    "return_corr = sec_returns.corr()\n",
    "return_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX THISSS\n",
    "# Calculating Diversifiable and Non-Diversifiable\n",
    "\n",
    "# Portfolio variance\n",
    "pflio_var = np.dot(my_portfolio['Weight'].T, np.dot(sec_returns.cov()*250, my_portfolio['Weight']))\n",
    "print(\"Portfolio Variance\", pflio_var)\n",
    "\n",
    "# Portfolio volatility \n",
    "#pflio_vol = (np.dot(my_portfolio['Weight'].T, np.dot(sec_returns.cov()*250, my_portfolio['Weight'])))**.5\n",
    "#print(\"Portfolio Volatility:\", pflio_vol)\n",
    "\n",
    "# or...\n",
    "\n",
    "pflio_vol2 = np.sqrt(pflio_var)\n",
    "print(\"Portfolio Volatility:\", pflio_vol2)\n",
    "\n",
    "\n",
    "# Calculating variance annually for each tickers\n",
    "var_a = []\n",
    "for t in tickers:\n",
    "    var_a.append(sec_returns[t].var()*250)\n",
    "\n",
    "var_a = np.array(var_a)\n",
    "variances = pd.DataFrame({'Name':names_txt, 'Variance':var_a})\n",
    "print(\"\")\n",
    "# Diversifiable Risk\n",
    "# div_risk = pflio_var - my_portfolio['Weight'][0]**2*variances['Variance'][0] - ...\n",
    "#                  ... - my_portfolio['Weight'][n]**2*variances['Variance'][n]\n",
    "div_risk = 0   \n",
    "for i in range(len(my_portfolio)):\n",
    "    if i==0:\n",
    "        div_risk = pflio_var - my_portfolio['Weight'][0]**2*variances['Variance'][0]\n",
    "    else:\n",
    "        div_risk -= my_portfolio['Weight'][i]**2*variances['Variance'][i]\n",
    "print(\"Diversifiable Risk:\", div_risk)\n",
    "\n",
    "print(\"\")\n",
    "# Non Diversifiable Risk\n",
    "non_div_risk1 = pflio_var - div_risk\n",
    "print(\"Non-Diversifiable Risk:\", non_div_risk1)\n",
    "\n",
    "print(\"\")\n",
    "non_div_risk2 = 0\n",
    "for i in range(len(my_portfolio)):\n",
    "    non_div_risk2 += my_portfolio['Weight'][i]**2*variances['Variance'][i]\n",
    "    #print(my_portfolio['Name'][i], non_div_risk2)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Non-Diversifiable Risk:\", non_div_risk2)\n",
    "print(\"Non-Diversifiable Risk:\", non_div_risk2 == non_div_risk1)\n",
    "\n",
    "\n",
    "##test = my_portfolio['Weight'].diff()\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_assets = len(tickers)\n",
    "no_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflio_ret = []\n",
    "pflio_vol = [] \n",
    "pflio_wei = []\n",
    "\n",
    "for x in range(10000):\n",
    "    weights = np.random.random(no_assets)\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    pflio_wei.append(weights)\n",
    "    pflio_ret.append(np.sum(weights*sec_returns.mean())*250)\n",
    "    pflio_vol.append(np.sqrt(np.dot(weights.T, np.dot(sec_returns.cov()*250, weights))))\n",
    "    #print(x, weights)\n",
    "\n",
    "pflio_wei = np.array(pflio_wei)\n",
    "pflio_ret = np.array(pflio_ret)\n",
    "pflio_vol = np.array(pflio_vol)\n",
    "\n",
    "#print(np.sum(weights))\n",
    "#pflio_returns, pflio_volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflio_scenarios = pd.DataFrame({'Return': pflio_ret, 'Volatility': pflio_vol})\n",
    "pflio_scenarios = pflio_scenarios.sort_values('Return', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflio_scenarios.head()\n",
    "#pflio_scenarios['Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflio_scenarios.tail(3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient Frontier \n",
    "pflio_scenarios.plot(x='Volatility', y='Return', kind='scatter', figsize=(10,6));\n",
    "plt.xlabel('Expected Volatility')\n",
    "plt.ylabel('Expected Return')\n",
    "eff_front = plt.savefig(\"efficient_frontier2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Testing purposes\n",
    "pfolio_wei2 = []\n",
    "tickers2 = []\n",
    "#print(pflio_wei[3273])\n",
    "tickers2 = np.array(tickers)\n",
    "#print(tickers2)\n",
    "#print(np.sum(pflio_wei[3273]))\n",
    "pflio_wei2 = pflio_wei[3273]\n",
    "\n",
    "\n",
    "#ideal_portfolio = pd.DataFrame(columns=tickers2)\n",
    "#ideal_portfolio = pd.DataFrame({'Symbol': tickers2, 'Weights': pflio_wei2})\n",
    "ideal_portfolio = pd.DataFrame({'Weights': pflio_wei2})\n",
    "ideal_portfolio = pd.concat([symbols, ideal_portfolio], axis=1)\n",
    "ideal_portfolio.to_csv('ideal_weights.csv', index=False)\n",
    "ideal_portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(my_data/my_data.iloc[0]*100).plot(figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "regression = sns.pairplot(sec_returns[1:], kind=\"reg\")\n",
    "regression = regression.savefig(\"regression.png\")\n",
    "regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 15))\n",
    "heatmap = sns.heatmap(return_corr, annot=True, square=True, cmap='coolwarm')\n",
    "heatmap.savefig(\"heatmap.png\")\n",
    "heatmap\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
